{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Define directories and patterns\n",
    "au_directory = '/home/nishma/My Project/College_thesis/IFD/archive/small_dataset/Au'\n",
    "tp_directory = '/home/nishma/My Project/College_thesis/IFD/archive/small_dataset/Tp'\n",
    "au_pattern = r'Au_([a-z]{3})_(\\d{5})'\n",
    "tp_pattern = r'([a-z]{3})(\\d{5})_([a-z]{3})(\\d{5})'\n",
    "size = (128, 128)\n",
    "\n",
    "# Process images\n",
    "X, y = process_images(au_directory, tp_directory, au_pattern, tp_pattern, size=size)\n",
    "\n",
    "# Output shape\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load the MobileNetV2 model with pre-trained weights, excluding the top layers\n",
    "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "# Freeze the convolutional base of the model to retain pre-trained weights during initial training\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create the model architecture by adding custom layers on top of MobileNetV2\n",
    "inputs = tf.keras.Input(shape=(128, 128, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    " loss='binary_crossentropy',\n",
    " metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model architecture\n",
    "model.summary()\n",
    "\n",
    "# Now you can proceed with the training and validation split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(X, y, test_size=0.20, random_state=42, shuffle=True)\n",
    "\n",
    "# Now you can use the `train_images` and `train_labels` in your model training code\n",
    "history = model.fit(train_images, train_labels,\n",
    " validation_data=(test_images, test_labels),\n",
    " epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from PIL import Image, ImageFilter\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pathlib\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function to highlight the forged part in the image\n",
    "def highlight_forgery(subtracted_array):\n",
    "    gray_img = cv2.cvtColor(subtracted_array, cv2.COLOR_RGB2GRAY)\n",
    "    _, thresholded_img = cv2.threshold(gray_img, 30, 255, cv2.THRESH_BINARY)\n",
    "    edges = cv2.Canny(thresholded_img, 100, 200)\n",
    "    highlighted_img = cv2.applyColorMap(edges, cv2.COLORMAP_JET)\n",
    "    result = cv2.addWeighted(subtracted_array, 0.7, highlighted_img, 0.3, 0)\n",
    "    return result\n",
    "\n",
    "# Function to resize and subtract two images, and highlight the forgery\n",
    "def subtract_images(image1_path, image2_path, size=(128, 128)):\n",
    " try:\n",
    " img1 = Image.open(image1_path).convert('RGB')\n",
    " img2 = Image.open(image2_path).convert('RGB')\n",
    " img1 = img1.resize(size)\n",
    " img2 = img2.resize(size)\n",
    " img1_array = np.asarray(img1, dtype=np.int32)\n",
    " img2_array = np.asarray(img2, dtype=np.int32)\n",
    " subtracted_array = np.clip(np.abs(img1_array - img2_array), 0, 255).astype(np.uint8)\n",
    " highlighted_array = highlight_forgery(subtracted_array)\n",
    " return highlighted_array\n",
    " except Exception as e:\n",
    " print(f\"Error subtracting images: {e}\")\n",
    " return None\n",
    "\n",
    "# Function to find matching images by pattern\n",
    "def find_image_pairs(au_directory, tp_directory, au_pattern, tp_pattern):\n",
    " authentic_images = {}\n",
    " tampered_images = []\n",
    " au_regex = re.compile(au_pattern)\n",
    " tp_regex = re.compile(tp_pattern)\n",
    " for filename in os.listdir(au_directory):\n",
    " if filename.endswith(('.jpg', '.jpeg', '.png', '.tiff')):\n",
    " match = au_regex.search(filename)\n",
    " if match:\n",
    " prefix = match.group(1)\n",
    " symbol = match.group(2)\n",
    " authentic_images[(prefix, symbol)] = os.path.join(au_directory, filename)\n",
    " for filename in os.listdir(tp_directory):\n",
    " if filename.endswith(('.jpg', '.jpeg', '.png', '.tiff', '.tif')):\n",
    " tampered_images.append(os.path.join(tp_directory, filename))\n",
    " return authentic_images, tampered_images\n",
    "\n",
    "# Function to process matching images and append them to the dataset\n",
    "def process_images(au_directory, tp_directory, au_pattern, tp_pattern, size=(128, 128)):\n",
    " authentic_images, tampered_images = find_image_pairs(au_directory, tp_directory, au_pattern, tp_pattern)\n",
    " X, y = [], []\n",
    " for tampered_img in tampered_images:\n",
    " tampered_filename = os.path.basename(tampered_img)\n",
    " print(tampered_filename)\n",
    " tampered_match = re.search(tp_pattern, tampered_filename)\n",
    " print(tampered_match)\n",
    " if tampered_match:\n",
    " tp_prefix1 = tampered_match.group(1)\n",
    " tp_symbol1 = tampered_match.group(2)\n",
    " tp_prefix2 = tampered_match.group(3)\n",
    " tp_symbol2 = tampered_match.group(4)\n",
    " matching_auth_img1 = authentic_images.get((tp_prefix1, tp_symbol1), None)\n",
    " matching_auth_img2 = authentic_images.get((tp_prefix2, tp_symbol2), None)\n",
    " print(matching_auth_img1)\n",
    "\n",
    " if matching_auth_img1:\n",
    " processed_img1 = subtract_images(matching_auth_img1, tampered_img, size=size)\n",
    " if processed_img1 is not None:\n",
    " X.append(processed_img1)\n",
    " y.append(1) # Label for forged\n",
    "\n",
    " if matching_auth_img2:\n",
    " processed_img2 = subtract_images(matching_auth_img2, tampered_img, size=size)\n",
    " if processed_img2 is not None:\n",
    " X.append(processed_img2)\n",
    " y.append(1) # Label for forged\n",
    " if not in matching_auth_img1 and matching_auth_img2:\n",
    " print(f\"No matching authentic image found for tampered image: {tampered_filename}\")\n",
    " return np.array(X), np.array(y)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
