{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, classification_report, confusion_matrix,\n",
    "                             roc_auc_score, roc_curve)  # Import for ROC/AUC\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from PIL import Image, ImageChops, ImageEnhance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class ForgeryDetector:\n",
    "    def __init__(self, dataset_path, image_size=(160, 160)):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.image_size = image_size\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "        self.X_train = None\n",
    "        self.X_val = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_val = None\n",
    "        self.y_test = None\n",
    "\n",
    "    def gaussian_blur_difference(self, image):\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        diff = cv2.absdiff(gray, blurred)\n",
    "        diff_color = cv2.cvtColor(diff, cv2.COLOR_GRAY2BGR)\n",
    "        return diff_color\n",
    "\n",
    "    def error_level_analysis(self, image, quality=98):\n",
    "        try:\n",
    "            im = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            temp_compressed = 'temp_compressed.jpg'\n",
    "            im.save(temp_compressed, 'JPEG', quality=quality)\n",
    "            compressed = Image.open(temp_compressed)\n",
    "            ela_image = ImageChops.difference(im, compressed)\n",
    "            ela_image = ImageEnhance.Brightness(ela_image).enhance(5)\n",
    "            os.remove(temp_compressed)\n",
    "            ela_cv = cv2.cvtColor(np.array(ela_image), cv2.COLOR_RGB2BGR)\n",
    "            return ela_cv\n",
    "        except Exception as e:\n",
    "            print(f\"ELA Error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "        gb_diff = self.gaussian_blur_difference(image)\n",
    "        ela_image = self.error_level_analysis(image)\n",
    "\n",
    "        if ela_image is None:\n",
    "            return None\n",
    "\n",
    "        gb_resized = cv2.resize(gb_diff, self.image_size)\n",
    "        ela_resized = cv2.resize(ela_image, self.image_size)\n",
    "\n",
    "        combined = cv2.addWeighted(gb_resized, 0.2, ela_resized, 0.8, 0)\n",
    "        return combined\n",
    "\n",
    "    def prepare_dataset(self):\n",
    "        X, y = [], []\n",
    "\n",
    "        for class_name in ['Au', 'Tp']:\n",
    "            class_path = os.path.join(self.dataset_path, class_name)\n",
    "            label = 0 if class_name == 'Au' else 1\n",
    "\n",
    "            for img_file in os.listdir(class_path):\n",
    "                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg', '.tif', '.tiff','.bmp')):\n",
    "                    continue\n",
    "                img_path = os.path.join(class_path, img_file)\n",
    "                img = cv2.imread(img_path)\n",
    "                processed_img = self.preprocess_image(img)\n",
    "\n",
    "                if processed_img is not None:\n",
    "                    X.append(processed_img)\n",
    "                    y.append(label)\n",
    "\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        return X, y\n",
    "\n",
    "    def build_model(self):\n",
    "        input_tensor = Input(shape=(self.image_size[0], self.image_size[1], 3))\n",
    "        base_model = MobileNetV2(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_tensor=input_tensor\n",
    "        )\n",
    "\n",
    "        base_model.trainable = False\n",
    "\n",
    "        x = base_model.output\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(1024, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(512, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "        self.model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "        self.model.compile(\n",
    "            optimizer=Adam(learning_rate=1e-5),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return self.model\n",
    "\n",
    "    def train_model(self, X, y):\n",
    "        X = preprocess_input(X)\n",
    "\n",
    "        # Standard Data Splitting\n",
    "        X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val\n",
    "        )\n",
    "\n",
    "        self.X_train = X_train\n",
    "        self.X_val = X_val\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_val = y_val\n",
    "        self.y_test = y_test\n",
    "\n",
    "        print(\"Model Summary:\")\n",
    "        self.model.summary()\n",
    "\n",
    "        self.history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),  # Single validation set\n",
    "            epochs=50, # Adjust as needed\n",
    "            batch_size=32, # Adjust as needed\n",
    "            class_weight={0: 1., 1: 2.}  # If data is imbalanced\n",
    "        )\n",
    "        return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "    def plot_training_curves(self):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.history.history['accuracy'], label='Training Accuracy')\n",
    "        plt.plot(self.history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(self.history.history['loss'], label='Training Loss')\n",
    "        plt.plot(self.history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_curves.png')\n",
    "        plt.show()\n",
    "\n",
    "    def evaluate_model(self, X_test, y_test):\n",
    "        y_pred_proba = self.model.predict(X_test)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        print(\"\\nEvaluation on TEST Set:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=['Non-Forged', 'Forged'],\n",
    "                    yticklabels=['Non-Forged', 'Forged'])\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('confusion_matrix.png')\n",
    "        plt.show()\n",
    "\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label=f'ROC curve (area = {auc:.2f})')\n",
    "        plt.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset_path = '/home/ubuntu/SoftwareProjects/Personal/thesis_related/TestData'\n",
    "detector = ForgeryDetector(dataset_path)\n",
    "\n",
    "# 1. Prepare the dataset:\n",
    "X, y = detector.prepare_dataset()\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "detector.build_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = detector.train_model(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "detector.plot_training_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 5. Evaluate the model on the TEST set:\n",
    "test_metrics = detector.evaluate_model(X_test, y_test)\n",
    "print(\"\\nTest Metrics:\", test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "   # Optional: Evaluate on the validation set as well:\n",
    "    # val_metrics = detector.evaluate_model(X_val, y_val)\n",
    "    # print(\"\\nValidation Metrics:\", val_metrics)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
