{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "import cv2\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "\n",
    "def load_images_from_folder(folder, target_size=(224, 224), max_images=None):\n",
    "    \"\"\"\n",
    "    Load images from a folder with memory-efficient approach\n",
    "    \n",
    "    Args:\n",
    "        folder (str): Path to image folder\n",
    "        target_size (tuple): Resize images to this size\n",
    "        max_images (int, optional): Limit number of images loaded\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Images and corresponding labels\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # List all image files\n",
    "    image_files = [f for f in os.listdir(folder) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif'))]\n",
    "    \n",
    "    # Limit images if specified\n",
    "    if max_images:\n",
    "        image_files = image_files[:max_images]\n",
    "    \n",
    "    for filename in image_files:\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            # Read image\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            # Check if image was read successfully\n",
    "            if img is not None:\n",
    "                # Resize image\n",
    "                img = cv2.resize(img, target_size)\n",
    "                \n",
    "                # Convert BGR to RGB\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                # Normalize\n",
    "                img = img / 255.0\n",
    "                \n",
    "                images.append(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "    \n",
    "    return np.array(images)\n",
    "\n",
    "def load_casia2_dataset(dataset_path, max_images_per_class=None):\n",
    "    \"\"\"\n",
    "    Load CASIA2 dataset with memory efficiency\n",
    "    \n",
    "    Args:\n",
    "        dataset_path (str): Path to CASIA2 dataset\n",
    "        max_images_per_class (int, optional): Limit images per class\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Images and labels\n",
    "    \"\"\"\n",
    "    # Load authentic and tampered images\n",
    "    authentic_images = load_images_from_folder(\n",
    "        os.path.join(dataset_path, 'Au'), \n",
    "        max_images=max_images_per_class\n",
    "    )\n",
    "    tampered_images = load_images_from_folder(\n",
    "        os.path.join(dataset_path, 'Tp'), \n",
    "        max_images=max_images_per_class\n",
    "    )\n",
    "    \n",
    "    # Create labels\n",
    "    authentic_labels = np.zeros(len(authentic_images))\n",
    "    tampered_labels = np.ones(len(tampered_images))\n",
    "    \n",
    "    # Combine images and labels\n",
    "    images = np.concatenate([authentic_images, tampered_images])\n",
    "    labels = np.concatenate([authentic_labels, tampered_labels])\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "def create_hybrid_model(input_shape, learning_rate=0.0001):\n",
    "    \"\"\"\n",
    "    Create hybrid MobileNetV2 model for binary forgery detection\n",
    "    \n",
    "    Args:\n",
    "        input_shape (tuple): Input image shape\n",
    "        learning_rate (float): Initial learning rate\n",
    "    \n",
    "    Returns:\n",
    "        tensorflow.keras.Model: Compiled hybrid model\n",
    "    \"\"\"\n",
    "    # Base MobileNetV2 model\n",
    "    base_model = MobileNetV2(\n",
    "        input_shape=input_shape, \n",
    "        include_top=False, \n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Freeze base model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Add custom classification layers\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC()]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(X_train, X_test, y_train, y_test, input_shape):\n",
    "    \"\"\"\n",
    "    Train and evaluate the model\n",
    "    \n",
    "    Args:\n",
    "        X_train (numpy.ndarray): Training images\n",
    "        X_test (numpy.ndarray): Test images\n",
    "        y_train (numpy.ndarray): Training labels\n",
    "        y_test (numpy.ndarray): Test labels\n",
    "        input_shape (tuple): Input image shape\n",
    "    \n",
    "    Returns:\n",
    "        dict: Training results and metrics\n",
    "    \"\"\"\n",
    "    # Create model\n",
    "    model = create_hybrid_model(input_shape)\n",
    "    \n",
    "    # Data augmentation\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    \n",
    "    # Callbacks\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.2,\n",
    "        patience=3, \n",
    "        min_lr=0.00001\n",
    "    )\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # Model checkpoint\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        'best_casia2_model.keras',\n",
    "        save_best_only=True, \n",
    "        monitor='val_accuracy',\n",
    "        mode='max'\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        train_datagen.flow(X_train, y_train, batch_size=16),\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=20,\n",
    "        callbacks=[reduce_lr, early_stopping, model_checkpoint]\n",
    "    )\n",
    "    \n",
    "    # Evaluate model\n",
    "    test_loss, test_accuracy, test_auc = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_proba = model.predict(X_test).flatten()\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Authentic', 'Tampered']))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Authentic', 'Tampered'], \n",
    "                yticklabels=['Authentic', 'Tampered'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return {\n",
    "        'test_loss': test_loss,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_auc': test_auc\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    # Set random seed\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    # Dataset path (MODIFY THIS)\n",
    "    dataset_path = '/path/to/CASIA2/dataset'\n",
    "    \n",
    "    # Load dataset (limit images to prevent memory issues)\n",
    "    images, labels = load_casia2_dataset(dataset_path, max_images_per_class=500)\n",
    "    \n",
    "    # Print dataset info\n",
    "    print(f\"Total images: {len(images)}\")\n",
    "    print(f\"Authentic images: {np.sum(labels == 0)}\")\n",
    "    print(f\"Tampered images: {np.sum(labels == 1)}\")\n",
    "    \n",
    "    # Split dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        images, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "    )\n",
    "    \n",
    "    # Input shape\n",
    "    input_shape = (224, 224, 3)\n",
    "    \n",
    "    # Train and evaluate\n",
    "    results = train_model(X_train, X_test, y_train, y_test, input_shape)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nFinal Test Metrics:\")\n",
    "    print(f\"Test Loss: {results['test_loss']}\")\n",
    "    print(f\"Test Accuracy: {results['test_accuracy']}\")\n",
    "    print(f\"Test AUC: {results['test_auc']}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/logpoint/Documents/SoftwareProjects/Thesis/venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 691ms/step - accuracy: 0.4789 - auc_3: 0.4961 - loss: 1.0406 - val_accuracy: 0.5925 - val_auc_3: 0.6262 - val_loss: 0.6751 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 764ms/step - accuracy: 0.5658 - auc_3: 0.5923 - loss: 0.8671 - val_accuracy: 0.6300 - val_auc_3: 0.6849 - val_loss: 0.6447 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 654ms/step - accuracy: 0.6306 - auc_3: 0.6810 - loss: 0.7494 - val_accuracy: 0.6500 - val_auc_3: 0.7173 - val_loss: 0.6227 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 631ms/step - accuracy: 0.6439 - auc_3: 0.6936 - loss: 0.7544 - val_accuracy: 0.6575 - val_auc_3: 0.7163 - val_loss: 0.6447 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 751ms/step - accuracy: 0.6674 - auc_3: 0.7010 - loss: 0.7414 - val_accuracy: 0.6750 - val_auc_3: 0.7302 - val_loss: 0.6383 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 661ms/step - accuracy: 0.7117 - auc_3: 0.7693 - loss: 0.6378 - val_accuracy: 0.6950 - val_auc_3: 0.7464 - val_loss: 0.6259 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 587ms/step - accuracy: 0.6408 - auc_3: 0.7002 - loss: 0.7389 - val_accuracy: 0.6875 - val_auc_3: 0.7467 - val_loss: 0.6308 - learning_rate: 2.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 619ms/step - accuracy: 0.6587 - auc_3: 0.7309 - loss: 0.6851 - val_accuracy: 0.6800 - val_auc_3: 0.7466 - val_loss: 0.6390 - learning_rate: 2.0000e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 679ms/step - accuracy: 0.6732 - auc_3: 0.7474 - loss: 0.6547 - val_accuracy: 0.6750 - val_auc_3: 0.7455 - val_loss: 0.6467 - learning_rate: 2.0000e-05\n",
      "Epoch 1/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 684ms/step - accuracy: 0.6297 - auc_4: 0.6949 - loss: 0.7373 - val_accuracy: 0.6450 - val_auc_4: 0.7167 - val_loss: 0.6305 - learning_rate: 1.0000e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 729ms/step - accuracy: 0.6236 - auc_4: 0.6916 - loss: 0.7276 - val_accuracy: 0.6500 - val_auc_4: 0.7154 - val_loss: 0.6395 - learning_rate: 1.0000e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 697ms/step - accuracy: 0.6448 - auc_4: 0.6892 - loss: 0.7367 - val_accuracy: 0.6500 - val_auc_4: 0.7147 - val_loss: 0.6476 - learning_rate: 1.0000e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 682ms/step - accuracy: 0.6407 - auc_4: 0.6690 - loss: 0.7802 - val_accuracy: 0.6525 - val_auc_4: 0.7127 - val_loss: 0.6568 - learning_rate: 1.0000e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 709ms/step - accuracy: 0.6448 - auc_4: 0.7021 - loss: 0.7192 - val_accuracy: 0.6400 - val_auc_4: 0.7104 - val_loss: 0.6660 - learning_rate: 2.0000e-06\n",
      "Epoch 6/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 715ms/step - accuracy: 0.6306 - auc_4: 0.6677 - loss: 0.7685 - val_accuracy: 0.6450 - val_auc_4: 0.7085 - val_loss: 0.6756 - learning_rate: 2.0000e-06\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 612ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Authentic       0.66      0.60      0.63       200\n",
      "    Tampered       0.63      0.69      0.66       200\n",
      "\n",
      "    accuracy                           0.65       400\n",
      "   macro avg       0.65      0.65      0.64       400\n",
      "weighted avg       0.65      0.65      0.64       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def load_images_from_folder(folder, target_size=(224, 224), max_images=None):\n",
    "    \"\"\" Load images from a folder efficiently \"\"\"\n",
    "    images = []\n",
    "    image_files = [f for f in os.listdir(folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    if max_images:\n",
    "        image_files = image_files[:max_images]\n",
    "    \n",
    "    for filename in image_files:\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, target_size)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = img / 255.0  # Normalize\n",
    "                images.append(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "    \n",
    "    return np.array(images)\n",
    "\n",
    "def load_casia2_dataset(dataset_path, max_images_per_class=None):\n",
    "    \"\"\" Load CASIA2 dataset \"\"\"\n",
    "    authentic_images = load_images_from_folder(os.path.join(dataset_path, 'Au'), max_images=max_images_per_class)\n",
    "    tampered_images = load_images_from_folder(os.path.join(dataset_path, 'Tp'), max_images=max_images_per_class)\n",
    "    authentic_labels = np.zeros(len(authentic_images))\n",
    "    tampered_labels = np.ones(len(tampered_images))\n",
    "    images = np.concatenate([authentic_images, tampered_images])\n",
    "    labels = np.concatenate([authentic_labels, tampered_labels])\n",
    "    return images, labels\n",
    "\n",
    "def create_optimized_model(input_shape, learning_rate=0.0001):\n",
    "    \"\"\" Create an optimized MobileNetV2 model \"\"\"\n",
    "    base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "    base_model.trainable = False  # Freeze base layers initially\n",
    "    \n",
    "    # Custom top layers\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)  # Add Batch Normalization\n",
    "    x = Dropout(0.5)(x)           # Increase dropout for regularization\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.AUC()])\n",
    "    return model\n",
    "\n",
    "def train_model(X_train, X_test, y_train, y_test, input_shape):\n",
    "    \"\"\" Train the optimized model \"\"\"\n",
    "    model = create_optimized_model(input_shape)\n",
    "    \n",
    "    # Data Augmentation with more variations\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rotation_range=30,       # Larger rotation\n",
    "        width_shift_range=0.3,   \n",
    "        height_shift_range=0.3,\n",
    "        shear_range=0.3,         # Increased transformations\n",
    "        zoom_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,      # Include vertical flip\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # Callbacks\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        train_datagen.flow(X_train, y_train, batch_size=32),  # Increase batch size\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=30,  # Train for longer\n",
    "        callbacks=[reduce_lr, early_stopping, model_checkpoint]\n",
    "    )\n",
    "    \n",
    "    # Fine-tuning: Unfreeze base model and train\n",
    "    model.trainable = True\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-5),  # Lower learning rate\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.AUC()])\n",
    "    history_fine = model.fit(\n",
    "        train_datagen.flow(X_train, y_train, batch_size=32),\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=10,\n",
    "        callbacks=[reduce_lr, early_stopping]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    # Set random seeds for reproducibility\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    # Dataset path (MODIFY THIS)\n",
    "    dataset_path = './CASIA2/'\n",
    "    \n",
    "    # Load dataset\n",
    "    images, labels = load_casia2_dataset(dataset_path, max_images_per_class=1000)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "    \n",
    "    # Train and fine-tune the model\n",
    "    input_shape = (224, 224, 3)\n",
    "    model = train_model(X_train, X_test, y_train, y_test, input_shape)\n",
    "    \n",
    "    # Evaluate model\n",
    "    y_pred_proba = model.predict(X_test).flatten()\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Authentic', 'Tampered']))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 199\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1-Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1_score(y_test,\u001b[38;5;250m \u001b[39my_pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 199\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 156\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m    155\u001b[0m     dataset_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./CASIA22\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Update path\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[43mload_casia2_dataset_with_preprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_images\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# Split dataset\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 126\u001b[0m, in \u001b[0;36mload_casia2_dataset_with_preprocessing\u001b[0;34m(dataset_path, target_size, max_images)\u001b[0m\n\u001b[1;32m    124\u001b[0m image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, file)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m     preprocessed_img \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     images\u001b[38;5;241m.\u001b[39mappend(preprocessed_img)\n\u001b[1;32m    128\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(label)\n",
      "Cell \u001b[0;32mIn[13], line 94\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[0;34m(image_path, target_size)\u001b[0m\n\u001b[1;32m     91\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, target_size)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Generate ELA image\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m ela_image \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_ela_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m90\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m ela_image_resized \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(ela_image, target_size)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Extract wavelet noise\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 42\u001b[0m, in \u001b[0;36mgenerate_ela_image\u001b[0;34m(image_path, quality)\u001b[0m\n\u001b[1;32m     40\u001b[0m max_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m([ex[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m ex \u001b[38;5;129;01min\u001b[39;00m extrema]) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     41\u001b[0m scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255.0\u001b[39m \u001b[38;5;241m/\u001b[39m max_diff\n\u001b[0;32m---> 42\u001b[0m ela_image \u001b[38;5;241m=\u001b[39m \u001b[43mImageEnhance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBrightness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mela_image\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menhance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Convert to numpy and ensure uint8\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(ela_image)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n",
      "File \u001b[0;32m~/Documents/SoftwareProjects/Thesis/venv/lib/python3.12/site-packages/PIL/ImageEnhance.py:40\u001b[0m, in \u001b[0;36m_Enhance.enhance\u001b[0;34m(self, factor)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menhance\u001b[39m(\u001b[38;5;28mself\u001b[39m, factor: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Image\u001b[38;5;241m.\u001b[39mImage:\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    Returns an enhanced image.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    :rtype: :py:class:`~PIL.Image.Image`\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegenerate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/SoftwareProjects/Thesis/venv/lib/python3.12/site-packages/PIL/Image.py:3540\u001b[0m, in \u001b[0;36mblend\u001b[0;34m(im1, im2, alpha)\u001b[0m\n\u001b[1;32m   3538\u001b[0m im1\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m   3539\u001b[0m im2\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m-> 3540\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m im1\u001b[38;5;241m.\u001b[39m_new(\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import pywt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input, Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "def generate_ela_image(image_path, quality=90):\n",
    "    \"\"\"\n",
    "    Generate ELA image to highlight tampering artifacts.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the original image.\n",
    "        quality (int): Quality level for compression (JPEG).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: ELA image as uint8.\n",
    "    \"\"\"\n",
    "    original = Image.open(image_path).convert('RGB')\n",
    "    # Save as JPEG with specific quality\n",
    "    temp_path = 'temp_compressed.jpg'\n",
    "    original.save(temp_path, 'JPEG', quality=quality)\n",
    "    \n",
    "    # Reload compressed image\n",
    "    compressed = Image.open(temp_path)\n",
    "    \n",
    "    # Calculate the difference\n",
    "    ela_image = ImageChops.difference(original, compressed)\n",
    "    \n",
    "    # Enhance the difference for better visibility\n",
    "    extrema = ela_image.getextrema()\n",
    "    max_diff = max([ex[1] for ex in extrema]) or 1\n",
    "    scale = 255.0 / max_diff\n",
    "    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
    "    \n",
    "    # Convert to numpy and ensure uint8\n",
    "    return np.array(ela_image).astype(np.uint8)\n",
    "\n",
    "\n",
    "def extract_wavelet_noise(image_array):\n",
    "    \"\"\"\n",
    "    Extract noise using Discrete Wavelet Transform (DWT).\n",
    "    \n",
    "    Args:\n",
    "        image_array (np.ndarray): Input image as a numpy array.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Reconstructed noise image as uint8.\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)\n",
    "    gray = gray / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "    # Perform 2D wavelet transform\n",
    "    coeffs = pywt.wavedec2(gray, 'haar', level=2)\n",
    "    \n",
    "    # Zero out approximation coefficients to keep only noise\n",
    "    coeffs_H = list(coeffs)\n",
    "    coeffs_H[0] = np.zeros_like(coeffs_H[0])\n",
    "    \n",
    "    # Reconstruct image from modified coefficients\n",
    "    noise = pywt.waverec2(coeffs_H, 'haar')\n",
    "    \n",
    "    # Clip and rescale to uint8\n",
    "    noise = np.clip(noise * 255.0, 0, 255).astype(np.uint8)\n",
    "    return noise\n",
    "\n",
    "\n",
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Preprocess image by combining ELA and wavelet noise.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image.\n",
    "        target_size (tuple): Resize target dimensions.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Combined image with ELA and Wavelet Noise as 3 channels.\n",
    "    \"\"\"\n",
    "    # Read and resize image\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, target_size).astype(np.uint8)\n",
    "    \n",
    "    # Generate ELA image\n",
    "    ela_image = generate_ela_image(image_path, quality=90)\n",
    "    ela_image_resized = cv2.resize(ela_image, target_size)\n",
    "    \n",
    "    # Extract wavelet noise\n",
    "    wavelet_noise = extract_wavelet_noise(img)\n",
    "    wavelet_noise_resized = cv2.resize(wavelet_noise, target_size)\n",
    "    \n",
    "    # Combine original, ELA, and wavelet noise into 3 channels\n",
    "    combined = np.stack([img[:, :, 0], ela_image_resized[:, :, 0], wavelet_noise_resized], axis=-1)\n",
    "    return combined.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "\n",
    "def load_casia2_dataset_with_preprocessing(dataset_path, target_size=(224, 224), max_images=None):\n",
    "    \"\"\"\n",
    "    Load CASIA2 dataset with ELA + Wavelet Noise preprocessing.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): Path to the CASIA2 dataset.\n",
    "        target_size (tuple): Resize dimensions.\n",
    "        max_images (int): Maximum images per class.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Preprocessed images and labels.\n",
    "    \"\"\"\n",
    "    images, labels = [], []\n",
    "    for label, folder in enumerate(['Au', 'Tp']):  # Authentic = 0, Tampered = 1\n",
    "        folder_path = os.path.join(dataset_path, folder)\n",
    "        files = os.listdir(folder_path)[:max_images]\n",
    "        \n",
    "        for file in files:\n",
    "            image_path = os.path.join(folder_path, file)\n",
    "            try:\n",
    "                preprocessed_img = preprocess_image(image_path, target_size)\n",
    "                images.append(preprocessed_img)\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {e}\")\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "def create_mobilenetv2_model(input_shape, learning_rate=0.0001):\n",
    "    \"\"\" MobileNetV2 model with custom input shape (3 channels). \"\"\"\n",
    "    base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.AUC()])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    dataset_path = './CASIA22'  # Update path\n",
    "    X, y = load_casia2_dataset_with_preprocessing(dataset_path, max_images=1000)\n",
    "    \n",
    "    # Split dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    input_shape = (224, 224, 3)  # Updated to 9 channels\n",
    "    \n",
    "    # Compute class weights\n",
    "    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "    \n",
    "    # Data augmentation\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        brightness_range=[0.8, 1.2]\n",
    "    )\n",
    "    \n",
    "    train_generator = train_datagen.flow(X_train, y_train, batch_size=16)\n",
    "    \n",
    "    # Create model\n",
    "    model = create_mobilenetv2_model(input_shape)\n",
    "    \n",
    "    # Initial Training with Frozen Layers\n",
    "    model.fit(train_generator, epochs=10, validation_data=(X_test, y_test), class_weight=class_weights_dict)\n",
    "    \n",
    "    # Unfreeze the base model for fine-tuning\n",
    "    model.layers[1].trainable = True  # Unfreeze MobileNetV2 base model\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC()])\n",
    "    \n",
    "    # Fine-tune\n",
    "    model.fit(train_generator, epochs=20, validation_data=(X_test, y_test), class_weight=class_weights_dict)\n",
    "\n",
    "    # Evaluate model\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "    print(classification_report(y_test, y_pred, target_names=['Authentic', 'Tampered']))\n",
    "    print(f\"F1-Score: {f1_score(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-4:\n",
      "Process SpawnPoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-10:\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-12:\n",
      "Process SpawnPoolWorker-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-16:\n",
      "Process SpawnPoolWorker-15:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-17:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-18:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-19:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-20:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-21:\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-22:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-23:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-25:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-26:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-27:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-28:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-29:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-30:\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-31:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-32:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 369, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'preprocess_image_wrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 144\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved as mobilenetv2_casia2.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 119\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Load and preprocess dataset\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading and preprocessing dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 119\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mload_casia2_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Train/test split\u001b[39;00m\n\u001b[1;32m    122\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 82\u001b[0m, in \u001b[0;36mload_casia2_dataset\u001b[0;34m(dataset_path, target_size, max_images)\u001b[0m\n\u001b[1;32m     79\u001b[0m file_paths \u001b[38;5;241m=\u001b[39m [(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, file), target_size) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files]\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(cpu_count()) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m---> 82\u001b[0m     preprocessed_images \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_image_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_paths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m images\u001b[38;5;241m.\u001b[39mextend(preprocessed_images)\n\u001b[1;32m     85\u001b[0m labels\u001b[38;5;241m.\u001b[39mextend([label] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(preprocessed_images))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:634\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    632\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 634\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:334\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# --- ELA Image Generation ---\n",
    "def generate_ela_image(image_path, quality=90):\n",
    "    \"\"\"\n",
    "    Generate an ELA image to highlight tampering artifacts.\n",
    "    \"\"\"\n",
    "    original = Image.open(image_path).convert(\"RGB\")\n",
    "    temp_path = \"temp_compressed.jpg\"\n",
    "    original.save(temp_path, \"JPEG\", quality=quality)\n",
    "    compressed = Image.open(temp_path)\n",
    "    ela_image = ImageChops.difference(original, compressed)\n",
    "    extrema = ela_image.getextrema()\n",
    "    max_diff = max([ex[1] for ex in extrema]) or 1\n",
    "    scale = 255.0 / max_diff\n",
    "    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
    "    return np.array(ela_image).astype(np.uint8)\n",
    "\n",
    "\n",
    "# --- Wavelet Noise Extraction ---\n",
    "import pywt\n",
    "\n",
    "def extract_wavelet_noise(image_array):\n",
    "    \"\"\"\n",
    "    Extract noise using Discrete Wavelet Transform (DWT).\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY) / 255.0\n",
    "    coeffs = pywt.wavedec2(gray, \"haar\", level=2)\n",
    "    coeffs_H = list(coeffs)\n",
    "    coeffs_H[0] = np.zeros_like(coeffs_H[0])  # Zero out approximation coefficients\n",
    "    noise = pywt.waverec2(coeffs_H, \"haar\")\n",
    "    noise = np.clip(noise * 255.0, 0, 255).astype(np.uint8)\n",
    "    return noise\n",
    "\n",
    "\n",
    "# --- Preprocessing ---\n",
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Preprocess image by combining ELA and Wavelet Noise.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img, target_size)\n",
    "    \n",
    "    ela_image = generate_ela_image(image_path)\n",
    "    ela_resized = cv2.resize(ela_image, target_size)\n",
    "    \n",
    "    wavelet_noise = extract_wavelet_noise(img)\n",
    "    wavelet_resized = cv2.resize(wavelet_noise, target_size)\n",
    "    \n",
    "    combined = np.stack([img_resized[:, :, 0], ela_resized[:, :, 0], wavelet_resized], axis=-1)\n",
    "    return combined.astype(np.float32) / 255.0  # Normalize\n",
    "\n",
    "\n",
    "def preprocess_image_wrapper(args):\n",
    "    return preprocess_image(*args)\n",
    "\n",
    "\n",
    "def load_casia2_dataset(dataset_path, target_size=(224, 224), max_images=None):\n",
    "    \"\"\"\n",
    "    Load CASIA2 dataset with parallel preprocessing.\n",
    "    \"\"\"\n",
    "    images, labels = [], []\n",
    "    for label, folder in enumerate([\"Au\", \"Tp\"]):\n",
    "        folder_path = os.path.join(dataset_path, folder)\n",
    "        files = os.listdir(folder_path)[:max_images]\n",
    "        file_paths = [(os.path.join(folder_path, file), target_size) for file in files]\n",
    "        \n",
    "        with Pool(cpu_count()) as p:\n",
    "            preprocessed_images = p.map(preprocess_image_wrapper, file_paths)\n",
    "        \n",
    "        images.extend(preprocessed_images)\n",
    "        labels.extend([label] * len(preprocessed_images))\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "# --- Model Definition ---\n",
    "def create_mobilenetv2_model(input_shape, learning_rate=0.0001):\n",
    "    \"\"\"\n",
    "    Create MobileNetV2 model for binary classification.\n",
    "    \"\"\"\n",
    "    base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n",
    "    base_model.trainable = False  # Freeze base model layers\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\", tf.keras.metrics.AUC()])\n",
    "    return model\n",
    "\n",
    "\n",
    "# --- Main Training Pipeline ---\n",
    "def main():\n",
    "    dataset_path = \"./CASIA22\"  # Path to the CASIA2 dataset\n",
    "    target_size = (224, 224)\n",
    "    max_images = 1000  # Limit the number of images per class\n",
    "    \n",
    "    # Load and preprocess dataset\n",
    "    print(\"Loading and preprocessing dataset...\")\n",
    "    X, y = load_casia2_dataset(dataset_path, target_size, max_images)\n",
    "    \n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    \n",
    "    # Create model\n",
    "    input_shape = (224, 224, 3)\n",
    "    print(\"Creating model...\")\n",
    "    model = create_mobilenetv2_model(input_shape)\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Training model...\")\n",
    "    history = model.fit(X_train, y_train, batch_size=16, epochs=10, validation_data=(X_test, y_test))\n",
    "    \n",
    "    # Evaluate model\n",
    "    print(\"Evaluating model...\")\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "    print(classification_report(y_test, y_pred, target_names=[\"Authentic\", \"Tampered\"]))\n",
    "    \n",
    "    # Save model\n",
    "    model.save(\"mobilenetv2_casia2.h5\")\n",
    "    print(\"Model saved as mobilenetv2_casia2.h5\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
