{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import numpy as np\n",
    "\n",
    "def perform_ela(image_path, quality=90):\n",
    "    # Open the image\n",
    "    original = Image.open(image_path).convert('RGB')\n",
    "    # Save it temporarily with the given quality\n",
    "    compressed_path = \"temp.jpg\"\n",
    "    original.save(compressed_path, \"JPEG\", quality=quality)\n",
    "    # Open the compressed image\n",
    "    compressed = Image.open(compressed_path)\n",
    "    # Compute the difference\n",
    "    ela_image = ImageChops.difference(original, compressed)\n",
    "    # Enhance the differences\n",
    "    extrema = ela_image.getextrema()\n",
    "    max_diff = max([ex[1] for ex in extrema])\n",
    "    scale = 255.0 / max_diff if max_diff != 0 else 1\n",
    "    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
    "    return np.array(ela_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def prepare_dataset(au_dataset, tp_dataset):\n",
    "    auth_data = []\n",
    "    auth_labels = []\n",
    "    \n",
    "    for image_file in tqdm(os.listdir(au_dataset)):\n",
    "        if image_file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(au_dataset, image_file)\n",
    "            ela_image = perform_ela(image_path)\n",
    "            auth_data.append(ela_image)\n",
    "            auth_labels.append(0)\n",
    "    tp_data = []\n",
    "    tp_labels = []\n",
    "    for image_file in tqdm(os.listdir(tp_dataset)):\n",
    "        if image_file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(tp_dataset, image_file)\n",
    "            ela_image = perform_ela(image_path)\n",
    "            tp_data.append(ela_image)\n",
    "            tp_labels.append(1)\n",
    "\n",
    "    final_data = auth_data + tp_data\n",
    "    final_labels = auth_labels + tp_labels\n",
    "    print(len(final_data), len(final_labels))\n",
    "    \n",
    "    return np.array(final_data), np.array(final_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7492/7492 [00:50<00:00, 149.20it/s]\n",
      "100%|██████████| 5125/5125 [00:19<00:00, 265.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9501 9501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (9501,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Assuming data and labels are ready\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m data, labels \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCASIA22/Au\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCASIA22/Tp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 27\u001b[0m, in \u001b[0;36mprepare_dataset\u001b[0;34m(au_dataset, tp_dataset)\u001b[0m\n\u001b[1;32m     24\u001b[0m final_labels \u001b[38;5;241m=\u001b[39m auth_labels \u001b[38;5;241m+\u001b[39m tp_labels\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(final_data), \u001b[38;5;28mlen\u001b[39m(final_labels))\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_data\u001b[49m\u001b[43m)\u001b[49m, np\u001b[38;5;241m.\u001b[39marray(final_labels)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (9501,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the VGG19 model\n",
    "def create_model(input_shape):\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base_model.trainable = False  # Freeze the base model\n",
    "    \n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(2, activation='softmax')  # Binary classification\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Assuming data and labels are ready\n",
    "data, labels = prepare_dataset('CASIA22/Au', 'CASIA22/Tp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and split the data\n",
    "data = data / 255.0\n",
    "labels = to_categorical(labels, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the model\n",
    "input_shape = (data.shape[1], data.shape[2], data.shape[3])\n",
    "model = create_model(input_shape)\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
